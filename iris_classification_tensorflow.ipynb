{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_path = \"/home/aquib/Desktop/Iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5. ,  3.4,  1.6,  0.4],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 5.9,  3. ,  5.1,  1.8]]),      0  1  2\n",
       " 0    1  0  0\n",
       " 1    1  0  0\n",
       " 2    1  0  0\n",
       " 3    1  0  0\n",
       " 4    1  0  0\n",
       " 5    1  0  0\n",
       " 6    1  0  0\n",
       " 7    1  0  0\n",
       " 8    1  0  0\n",
       " 9    1  0  0\n",
       " 10   1  0  0\n",
       " 11   1  0  0\n",
       " 12   1  0  0\n",
       " 13   1  0  0\n",
       " 14   1  0  0\n",
       " 15   1  0  0\n",
       " 16   1  0  0\n",
       " 17   1  0  0\n",
       " 18   1  0  0\n",
       " 19   1  0  0\n",
       " 20   1  0  0\n",
       " 21   1  0  0\n",
       " 22   1  0  0\n",
       " 23   1  0  0\n",
       " 24   1  0  0\n",
       " 25   1  0  0\n",
       " 26   1  0  0\n",
       " 27   1  0  0\n",
       " 28   1  0  0\n",
       " 29   1  0  0\n",
       " ..  .. .. ..\n",
       " 120  0  0  1\n",
       " 121  0  0  1\n",
       " 122  0  0  1\n",
       " 123  0  0  1\n",
       " 124  0  0  1\n",
       " 125  0  0  1\n",
       " 126  0  0  1\n",
       " 127  0  0  1\n",
       " 128  0  0  1\n",
       " 129  0  0  1\n",
       " 130  0  0  1\n",
       " 131  0  0  1\n",
       " 132  0  0  1\n",
       " 133  0  0  1\n",
       " 134  0  0  1\n",
       " 135  0  0  1\n",
       " 136  0  0  1\n",
       " 137  0  0  1\n",
       " 138  0  0  1\n",
       " 139  0  0  1\n",
       " 140  0  0  1\n",
       " 141  0  0  1\n",
       " 142  0  0  1\n",
       " 143  0  0  1\n",
       " 144  0  0  1\n",
       " 145  0  0  1\n",
       " 146  0  0  1\n",
       " 147  0  0  1\n",
       " 148  0  0  1\n",
       " 149  0  0  1\n",
       " \n",
       " [150 rows x 3 columns])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data():\n",
    "    data = pd.read_csv(data_path)\n",
    "    x_lables = np.array(data.iloc[0:150,[1,2,3,4]].values)\n",
    "    y_lable = data.iloc[0:150,[5]].values\n",
    "    \n",
    "    y = []\n",
    "    value = []\n",
    "    for i in y_lable:\n",
    "        if i not in value:\n",
    "            value.append(i)\n",
    "\n",
    "    for i in y_lable:\n",
    "        y.append(value.index(i))\n",
    "        \n",
    "    y_lable = pd.get_dummies(y)\n",
    "    return x_lables,y_lable\n",
    "\n",
    "    \n",
    "read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_lables, y_lable = read_data()\n",
    "\n",
    "X_input = tf.placeholder(tf.float32, [None,4])\n",
    "y_output = tf.placeholder(tf.float32, [None,3])\n",
    "\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([4,5]), name = \"Weights_1\")\n",
    "b1 = tf.Variable(tf.random_normal([1,5]), name = \"Bias_1\")\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([5,3]),  name = \"Weights_2\")\n",
    "b2 = tf.Variable(tf.random_normal([1,3]), name = \"Bias_2\")\n",
    "#print \"weight_2 before Iteration: \",w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************weights before training*********************************\n",
      "                                                                                \n",
      "weight_1: \n",
      "[[ -4.17683423e-01   1.26511633e+00   4.24637258e-01   1.15733683e+00\n",
      "   -7.54366755e-01]\n",
      " [ -1.41512227e+00  -7.60820210e-01   4.09764834e-02  -4.73701328e-01\n",
      "    1.16874361e+00]\n",
      " [ -8.04364011e-02  -9.50930238e-01   1.73865934e-03  -3.24605741e-02\n",
      "    8.00050795e-01]\n",
      " [  8.83699834e-01  -2.74147034e-01   4.52570349e-01   2.05774975e+00\n",
      "   -5.05107582e-01]]\n",
      "weight_2: \n",
      "[[-0.87454176 -0.77493054  1.32994819]\n",
      " [-0.81558901  0.61828578  0.37749916]\n",
      " [ 1.09900236 -0.40082777  0.4573271 ]\n",
      " [ 0.78624749 -0.75187039 -0.02564553]\n",
      " [ 0.80824882 -0.80396068  1.24323571]]\n",
      "-------------------------Training Result------------------------------------------\n",
      "                                                                                 \n",
      "losses after per 1000 iteration:  0.319213\n",
      "losses after per 1000 iteration:  0.0803356\n",
      "losses after per 1000 iteration:  0.035154\n",
      "losses after per 1000 iteration:  0.0215083\n",
      "losses after per 1000 iteration:  0.0171508\n",
      "*****************************weight after training*************************************\n",
      "weight_1 after trainig: \n",
      "[[-1.62538791  1.59258771  0.63649541  1.23606777 -1.28317738]\n",
      " [-1.95732605 -0.75708592  0.22114548 -0.41934535 -0.18298885]\n",
      " [ 2.52332258 -0.39011312 -0.00777279 -0.00990405  2.82821131]\n",
      " [ 3.1848228  -0.06749131  0.43072829  2.0607245   0.84251648]]\n",
      "weight_2 after training: \n",
      "[[-2.44231176 -2.66903424  4.79182577]\n",
      " [-0.175595    1.02962983 -0.67383361]\n",
      " [ 1.66965699  0.02918324 -0.5433386 ]\n",
      " [ 1.39809036 -0.32546398 -1.06389391]\n",
      " [-4.05635262  2.51167917  2.79218769]]\n",
      "-------------------------------------Results--------------------------------------------\n",
      "                                                                                         \n",
      "Result:   [[ 0.00170178  0.0427179   0.95558035]]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer = tf.nn.sigmoid(tf.matmul(X_input,w1)+b1)\n",
    "output_layer = tf.nn.softmax(tf.matmul(hidden_layer,w2) + b2)\n",
    "\n",
    "losses = tf.losses.mean_squared_error(y_lable,output_layer)\n",
    "\n",
    "#optimizer = tf.train.AdamOptimizer(0.001).minimize(losses)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.09).minimize(losses)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print \"************************weights before training*********************************\"\n",
    "print \"                                                                                \"\n",
    "we1,we2 = sess.run([w1,w2])\n",
    "print \"weight_1: \"\n",
    "print we1\n",
    "print \"weight_2: \"\n",
    "print we2\n",
    "\n",
    "print \"-------------------------Training Result------------------------------------------\"\n",
    "print \"                                                                                 \"\n",
    "\n",
    "step_size = 10000\n",
    "for step in range(step_size):\n",
    "    \n",
    "    a,b,c,d,e,f = sess.run([hidden_layer,output_layer,losses,optimizer,w1,w2], feed_dict={X_input:x_lables,y_output:y_lable})\n",
    "    \n",
    "    if step%2000==0:\n",
    "        \n",
    "        print \"losses after per 1000 iteration: \",c\n",
    "\n",
    "check = tf.nn.sigmoid(tf.matmul([[6.8,3.2,5.9,2.3]],w1)+b1)\n",
    "output = tf.nn.softmax(tf.matmul(check,w2) + b2)\n",
    "\n",
    "print \"*****************************weight after training*************************************\"\n",
    "print \"weight_1 after trainig: \"\n",
    "print e\n",
    "print \"weight_2 after training: \"\n",
    "print f\n",
    "\n",
    "a,b = sess.run([check,output])\n",
    "#print (output)\n",
    "print \"-------------------------------------Results--------------------------------------------\"\n",
    "print \"                                                                                         \"\n",
    "print \"Result:  \",b\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
