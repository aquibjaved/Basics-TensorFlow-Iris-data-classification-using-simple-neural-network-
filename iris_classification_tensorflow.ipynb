{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_path = \"/home/aquib/Desktop/Iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 5. ,  3.4,  1.6,  0.4],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 5.9,  3. ,  5.1,  1.8],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 5. ,  2. ,  3.5,  1. ]]),      0  1  2\n",
       " 0    1  0  0\n",
       " 1    1  0  0\n",
       " 2    0  1  0\n",
       " 3    0  1  0\n",
       " 4    0  0  1\n",
       " 5    1  0  0\n",
       " 6    0  1  0\n",
       " 7    0  1  0\n",
       " 8    0  0  1\n",
       " 9    1  0  0\n",
       " 10   0  0  1\n",
       " 11   0  1  0\n",
       " 12   0  0  1\n",
       " 13   0  0  1\n",
       " 14   0  1  0\n",
       " 15   1  0  0\n",
       " 16   1  0  0\n",
       " 17   0  1  0\n",
       " 18   0  1  0\n",
       " 19   1  0  0\n",
       " 20   0  1  0\n",
       " 21   0  0  1\n",
       " 22   1  0  0\n",
       " 23   0  0  1\n",
       " 24   0  1  0\n",
       " 25   1  0  0\n",
       " 26   0  1  0\n",
       " 27   0  1  0\n",
       " 28   1  0  0\n",
       " 29   0  1  0\n",
       " ..  .. .. ..\n",
       " 120  0  0  1\n",
       " 121  0  0  1\n",
       " 122  0  1  0\n",
       " 123  1  0  0\n",
       " 124  0  1  0\n",
       " 125  1  0  0\n",
       " 126  0  0  1\n",
       " 127  0  1  0\n",
       " 128  1  0  0\n",
       " 129  0  1  0\n",
       " 130  0  0  1\n",
       " 131  0  0  1\n",
       " 132  0  1  0\n",
       " 133  0  0  1\n",
       " 134  0  0  1\n",
       " 135  0  0  1\n",
       " 136  1  0  0\n",
       " 137  1  0  0\n",
       " 138  0  1  0\n",
       " 139  0  1  0\n",
       " 140  0  1  0\n",
       " 141  0  1  0\n",
       " 142  0  0  1\n",
       " 143  0  0  1\n",
       " 144  1  0  0\n",
       " 145  0  1  0\n",
       " 146  1  0  0\n",
       " 147  1  0  0\n",
       " 148  1  0  0\n",
       " 149  1  0  0\n",
       " \n",
       " [150 rows x 3 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data():\n",
    "    data = pd.read_csv(data_path) #read the data\n",
    "    data = data.reindex(np.random.permutation(data.index)) #shuffling the data\n",
    "\n",
    "    x_lables = np.array(data.iloc[0:150,[1,2,3,4]].values) \n",
    "    y_lable = data.iloc[0:150,[5]].values\n",
    "    \n",
    "    y = []\n",
    "    value = []\n",
    "    for i in y_lable:\n",
    "        if i not in value:\n",
    "            value.append(i)\n",
    "\n",
    "    for i in y_lable:\n",
    "        y.append(value.index(i))\n",
    "        \n",
    "    y_lable = pd.get_dummies(y)\n",
    "    return x_lables,y_lable\n",
    "\n",
    "    \n",
    "read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_lables, y_lable = read_data()\n",
    "\n",
    "X_input = tf.placeholder(tf.float32, [None,4]) #creating palce holder for the holding the input value data will be feed during runtime\n",
    "y_output = tf.placeholder(tf.float32, [None,3]) #creating placeholder for holding the actual label the data will feed during the run time\n",
    "\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([4,5]), name = \"Weights_1\") #Initaliazing weight_1\n",
    "b1 = tf.Variable(tf.random_normal([1,5]), name = \"Bias_1\")\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([5,3]),  name = \"Weights_2\") #Initaliazing weight_2\n",
    "b2 = tf.Variable(tf.random_normal([1,3]), name = \"Bias_2\")\n",
    "#print \"weight_2 before Iteration: \",w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************weights before training*********************************\n",
      "                                                                                \n",
      "weight_1: \n",
      "[[ 0.80603981 -0.21456876  0.47271857 -0.35710388 -1.093413  ]\n",
      " [ 1.03609419 -0.55417347  1.59926617 -0.43003097 -0.61598533]\n",
      " [ 0.84522825 -0.2183467   0.5043003   0.90745598  1.56870425]\n",
      " [-2.31897712  0.31366342 -0.65608186  0.75571901  0.23725617]]\n",
      "weight_2: \n",
      "[[-0.89052844  0.32948658  0.32773978]\n",
      " [ 0.40159386 -1.07772005  2.24560618]\n",
      " [ 0.66951072  0.25132018 -0.68593705]\n",
      " [-1.10515797  1.34196305  0.44815379]\n",
      " [-2.69940996 -0.06878625  1.24937367]]\n",
      "-------------------------Training Result------------------------------------------\n",
      "                                                                                 \n",
      "losses after per 1000 iteration:  0.324689\n",
      "losses after per 1000 iteration:  0.0356117\n",
      "losses after per 1000 iteration:  0.0224626\n",
      "losses after per 1000 iteration:  0.0180354\n",
      "losses after per 1000 iteration:  0.0158285\n",
      "                                                                                         \n",
      "-------------------------------------Accuracy--------------------------------------------\n",
      "                                                                                         \n",
      "Accuracy on the model:  0.98\n",
      "***************************** weight after training *************************************\n",
      "weight_1 after trainig: \n",
      "[[ 0.80210078 -0.31278285  0.56879741 -1.03160501 -2.15265369]\n",
      " [ 1.03727651 -1.61247194  1.64444721 -0.69112527 -2.02547908]\n",
      " [ 0.83577228  2.0863595   0.56509137  0.30745107  3.17404056]\n",
      " [-2.32218742  1.40607727 -0.64068878  0.56250948  2.98638821]]\n",
      "weight_2 after training: \n",
      "[[-1.01559544  1.2651701  -0.48287472]\n",
      " [ 3.41042233 -3.97029757  2.12939477]\n",
      " [ 0.5407331   1.18163896 -1.48747325]\n",
      " [-1.04159057  1.08107185  0.64543152]\n",
      " [-4.00411654 -1.4649421   3.95023108]]\n",
      "-------------------------------------Results--------------------------------------------\n",
      "                                                                                         \n",
      "Result:   [[ 0.03290041  0.00617945  0.96092016]]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer = tf.nn.sigmoid(tf.matmul(X_input,w1)+b1) \n",
    "output_layer = tf.nn.softmax(tf.matmul(hidden_layer,w2) + b2)\n",
    "\n",
    "losses = tf.losses.mean_squared_error(y_lable,output_layer)\n",
    "\n",
    "#optimizer = tf.train.AdamOptimizer(0.001).minimize(losses)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.09).minimize(losses)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print \"************************weights before training*********************************\"\n",
    "print \"                                                                                \"\n",
    "\n",
    "\n",
    "we1,we2 = sess.run([w1,w2])\n",
    "print \"weight_1: \"\n",
    "print we1\n",
    "print \"weight_2: \"\n",
    "print we2\n",
    "\n",
    "print \"-------------------------Training Result------------------------------------------\"\n",
    "print \"                                                                                 \"\n",
    "\n",
    "step_size = 10000\n",
    "for step in range(step_size):\n",
    "    \n",
    "    a,b,c,d,e,f = sess.run([hidden_layer,output_layer,losses,optimizer,w1,w2], feed_dict={X_input:x_lables,y_output:y_lable})\n",
    "\n",
    "    if step%2000==0:\n",
    "        print \"losses after per 1000 iteration: \",c\n",
    "\n",
    "print \"                                                                                         \"       \n",
    "correct_prediction = tf.equal(tf.argmax(output_layer,1), tf.argmax(y_output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print \"-------------------------------------Accuracy--------------------------------------------\"\n",
    "print \"                                                                                         \"\n",
    "\n",
    "print \"Accuracy on the model: \",accuracy.eval(feed_dict={X_input:x_lables, y_output:y_lable})\n",
    "\n",
    "check = tf.nn.sigmoid(tf.matmul([[6.8,3.2,5.9,2.3]],w1)+b1)\n",
    "output = tf.nn.softmax(tf.matmul(check,w2) + b2)\n",
    "\n",
    "print \"***************************** weight after training *************************************\"\n",
    "print \"weight_1 after trainig: \"\n",
    "print e\n",
    "print \"weight_2 after training: \"\n",
    "print f\n",
    "\n",
    "a,b = sess.run([check,output])\n",
    "#print (output)\n",
    "print \"-------------------------------------Results--------------------------------------------\"\n",
    "print \"                                                                                         \"\n",
    "print \"Result:  \",b\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
