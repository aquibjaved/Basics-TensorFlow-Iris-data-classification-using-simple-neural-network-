{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_path = \"/home/aquib/Desktop/Iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5. ,  3.4,  1.6,  0.4],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 5.9,  3. ,  5.1,  1.8]]),      0  1  2\n",
       " 0    1  0  0\n",
       " 1    1  0  0\n",
       " 2    1  0  0\n",
       " 3    1  0  0\n",
       " 4    1  0  0\n",
       " 5    1  0  0\n",
       " 6    1  0  0\n",
       " 7    1  0  0\n",
       " 8    1  0  0\n",
       " 9    1  0  0\n",
       " 10   1  0  0\n",
       " 11   1  0  0\n",
       " 12   1  0  0\n",
       " 13   1  0  0\n",
       " 14   1  0  0\n",
       " 15   1  0  0\n",
       " 16   1  0  0\n",
       " 17   1  0  0\n",
       " 18   1  0  0\n",
       " 19   1  0  0\n",
       " 20   1  0  0\n",
       " 21   1  0  0\n",
       " 22   1  0  0\n",
       " 23   1  0  0\n",
       " 24   1  0  0\n",
       " 25   1  0  0\n",
       " 26   1  0  0\n",
       " 27   1  0  0\n",
       " 28   1  0  0\n",
       " 29   1  0  0\n",
       " ..  .. .. ..\n",
       " 120  0  0  1\n",
       " 121  0  0  1\n",
       " 122  0  0  1\n",
       " 123  0  0  1\n",
       " 124  0  0  1\n",
       " 125  0  0  1\n",
       " 126  0  0  1\n",
       " 127  0  0  1\n",
       " 128  0  0  1\n",
       " 129  0  0  1\n",
       " 130  0  0  1\n",
       " 131  0  0  1\n",
       " 132  0  0  1\n",
       " 133  0  0  1\n",
       " 134  0  0  1\n",
       " 135  0  0  1\n",
       " 136  0  0  1\n",
       " 137  0  0  1\n",
       " 138  0  0  1\n",
       " 139  0  0  1\n",
       " 140  0  0  1\n",
       " 141  0  0  1\n",
       " 142  0  0  1\n",
       " 143  0  0  1\n",
       " 144  0  0  1\n",
       " 145  0  0  1\n",
       " 146  0  0  1\n",
       " 147  0  0  1\n",
       " 148  0  0  1\n",
       " 149  0  0  1\n",
       " \n",
       " [150 rows x 3 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data():\n",
    "    data = pd.read_csv(data_path)\n",
    "    x_lables = np.array(data.iloc[0:150,[1,2,3,4]].values)\n",
    "    y_lable = data.iloc[0:150,[5]].values\n",
    "    \n",
    "    y = []\n",
    "    value = []\n",
    "    for i in y_lable:\n",
    "        if i not in value:\n",
    "            value.append(i)\n",
    "\n",
    "    for i in y_lable:\n",
    "        y.append(value.index(i))\n",
    "        \n",
    "    y_lable = pd.get_dummies(y)\n",
    "    return x_lables,y_lable\n",
    "\n",
    "    \n",
    "read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_lables, y_lable = read_data()\n",
    "\n",
    "X_input = tf.placeholder(tf.float32, [None,4])\n",
    "y_output = tf.placeholder(tf.float32, [None,3])\n",
    "\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([4,5]), name = \"Weights_1\")\n",
    "b1 = tf.Variable(tf.random_normal([1,5]), name = \"Bias_1\")\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([5,3]),  name = \"Weights_2\")\n",
    "b2 = tf.Variable(tf.random_normal([1,3]), name = \"Bias_2\")\n",
    "#print \"weight_2 before Iteration: \",w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************weights before training*********************************\n",
      "                                                                                \n",
      "weight_1: \n",
      "[[-1.06670809  1.42747211 -0.93775493 -1.62082124  1.34094393]\n",
      " [ 1.3183161   0.1441863  -1.81486189 -0.12378923 -0.62717527]\n",
      " [-0.36196601 -0.30769157 -0.43646875  1.05228233 -0.09818513]\n",
      " [ 0.85040385  1.34288156  0.86009032 -0.50265473  1.93989444]]\n",
      "weight_2: \n",
      "[[-0.46068481 -0.85009849 -1.35885608]\n",
      " [-1.60727787 -1.84002161 -0.35146952]\n",
      " [ 1.22007835 -0.20734677  1.26633024]\n",
      " [ 0.63400757  1.12092662 -1.47261846]\n",
      " [-1.02548909  1.02697837 -0.75949943]]\n",
      "-------------------------Training Result------------------------------------------\n",
      "                                                                                 \n",
      "losses after per 1000 iteration:  0.282865\n",
      "losses after per 1000 iteration:  0.11148\n",
      "losses after per 1000 iteration:  0.0487605\n",
      "losses after per 1000 iteration:  0.0245723\n",
      "losses after per 1000 iteration:  0.0179252\n",
      "                                                                                         \n",
      "-------------------------------------Accuracy--------------------------------------------\n",
      "                                                                                         \n",
      "Accuracy on the model:  0.986667\n",
      "***************************** weight after training *************************************\n",
      "weight_1 after trainig: \n",
      "[[  1.50436080e+00   1.42663622e+00  -9.46081579e-01  -1.36261904e+00\n",
      "    3.84052128e-01]\n",
      " [  1.84749448e+00   1.43996462e-01  -1.81770027e+00   1.91819400e-03\n",
      "   -2.05128407e+00]\n",
      " [ -2.78931093e+00  -3.08652520e-01  -4.42843437e-01   9.87628698e-01\n",
      "    1.30329680e+00]\n",
      " [ -2.57965469e+00   1.34269476e+00   8.58438313e-01  -6.43085659e-01\n",
      "    2.55929351e+00]]\n",
      "weight_2 after training: \n",
      "[[ 2.81569433  0.90961212 -6.39494085]\n",
      " [-1.34335756 -2.82782745  0.37243441]\n",
      " [ 1.22017157 -0.20635606  1.2653904 ]\n",
      " [ 0.61165076  1.16742456 -1.4967252 ]\n",
      " [-3.55834675  2.16393924  0.6363914 ]]\n",
      "-------------------------------------Results--------------------------------------------\n",
      "                                                                                         \n",
      "Result:   [[  5.13052102e-04   5.19091673e-02   9.47577834e-01]]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer = tf.nn.sigmoid(tf.matmul(X_input,w1)+b1)\n",
    "output_layer = tf.nn.softmax(tf.matmul(hidden_layer,w2) + b2)\n",
    "\n",
    "losses = tf.losses.mean_squared_error(y_lable,output_layer)\n",
    "\n",
    "#optimizer = tf.train.AdamOptimizer(0.001).minimize(losses)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.09).minimize(losses)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print \"************************weights before training*********************************\"\n",
    "print \"                                                                                \"\n",
    "\n",
    "\n",
    "we1,we2 = sess.run([w1,w2])\n",
    "print \"weight_1: \"\n",
    "print we1\n",
    "print \"weight_2: \"\n",
    "print we2\n",
    "\n",
    "print \"-------------------------Training Result------------------------------------------\"\n",
    "print \"                                                                                 \"\n",
    "\n",
    "step_size = 10000\n",
    "for step in range(step_size):\n",
    "    \n",
    "    a,b,c,d,e,f = sess.run([hidden_layer,output_layer,losses,optimizer,w1,w2], feed_dict={X_input:x_lables,y_output:y_lable})\n",
    "\n",
    "    if step%2000==0:\n",
    "        print \"losses after per 1000 iteration: \",c\n",
    "\n",
    "print \"                                                                                         \"       \n",
    "correct_prediction = tf.equal(tf.argmax(output_layer,1), tf.argmax(y_output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print \"-------------------------------------Accuracy--------------------------------------------\"\n",
    "print \"                                                                                         \"\n",
    "\n",
    "print \"Accuracy on the model: \",accuracy.eval(feed_dict={X_input:x_lables, y_output:y_lable})\n",
    "\n",
    "check = tf.nn.sigmoid(tf.matmul([[6.8,3.2,5.9,2.3]],w1)+b1)\n",
    "output = tf.nn.softmax(tf.matmul(check,w2) + b2)\n",
    "\n",
    "print \"***************************** weight after training *************************************\"\n",
    "print \"weight_1 after trainig: \"\n",
    "print e\n",
    "print \"weight_2 after training: \"\n",
    "print f\n",
    "\n",
    "a,b = sess.run([check,output])\n",
    "#print (output)\n",
    "print \"-------------------------------------Results--------------------------------------------\"\n",
    "print \"                                                                                         \"\n",
    "print \"Result:  \",b\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
