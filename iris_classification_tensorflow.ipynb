{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "data_path = \"/home/aquib/Desktop/Iris.csv\" #path to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 4.6,  3.2,  1.4,  0.2],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.4,  1.6,  0.4],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 5.9,  3. ,  5.1,  1.8],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 6.8,  3. ,  5.5,  2.1]]),      0  1  2\n",
       " 0    1  0  0\n",
       " 1    0  1  0\n",
       " 2    1  0  0\n",
       " 3    1  0  0\n",
       " 4    0  0  1\n",
       " 5    0  0  1\n",
       " 6    0  1  0\n",
       " 7    0  1  0\n",
       " 8    0  0  1\n",
       " 9    0  1  0\n",
       " 10   0  0  1\n",
       " 11   0  1  0\n",
       " 12   0  1  0\n",
       " 13   1  0  0\n",
       " 14   0  0  1\n",
       " 15   1  0  0\n",
       " 16   1  0  0\n",
       " 17   0  1  0\n",
       " 18   0  1  0\n",
       " 19   1  0  0\n",
       " 20   0  0  1\n",
       " 21   0  1  0\n",
       " 22   0  0  1\n",
       " 23   1  0  0\n",
       " 24   0  1  0\n",
       " 25   1  0  0\n",
       " 26   0  0  1\n",
       " 27   0  0  1\n",
       " 28   0  0  1\n",
       " 29   0  0  1\n",
       " ..  .. .. ..\n",
       " 120  1  0  0\n",
       " 121  1  0  0\n",
       " 122  0  0  1\n",
       " 123  1  0  0\n",
       " 124  0  0  1\n",
       " 125  1  0  0\n",
       " 126  0  0  1\n",
       " 127  0  1  0\n",
       " 128  0  0  1\n",
       " 129  1  0  0\n",
       " 130  0  0  1\n",
       " 131  1  0  0\n",
       " 132  1  0  0\n",
       " 133  0  0  1\n",
       " 134  1  0  0\n",
       " 135  0  0  1\n",
       " 136  0  1  0\n",
       " 137  0  1  0\n",
       " 138  1  0  0\n",
       " 139  0  0  1\n",
       " 140  0  1  0\n",
       " 141  1  0  0\n",
       " 142  0  1  0\n",
       " 143  0  1  0\n",
       " 144  1  0  0\n",
       " 145  0  0  1\n",
       " 146  1  0  0\n",
       " 147  0  1  0\n",
       " 148  0  0  1\n",
       " 149  0  1  0\n",
       " \n",
       " [150 rows x 3 columns])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data():\n",
    "    data = pd.read_csv(data_path) #read the data\n",
    "    data = data.reindex(np.random.permutation(data.index)) #shuffling the data\n",
    "\n",
    "    x_lables = np.array(data.iloc[0:150,[1,2,3,4]].values) \n",
    "    y_lable = data.iloc[0:150,[5]].values\n",
    "    \n",
    "    y = []\n",
    "    value = []\n",
    "    for i in y_lable:\n",
    "        if i not in value:\n",
    "            value.append(i)\n",
    "\n",
    "    for i in y_lable:\n",
    "        y.append(value.index(i))\n",
    "        \n",
    "    y_lable = pd.get_dummies(y)\n",
    "    return x_lables,y_lable\n",
    "\n",
    "    \n",
    "read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[ 0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "x_lables, y_lable = read_data()\n",
    "\n",
    "X_input = tf.placeholder(tf.float32, [None,4]) #creating palce holder for the holding the input value data will be feed during runtime\n",
    "y_output = tf.placeholder(tf.float32, [None,3]) #creating placeholder for holding the actual label the data will feed during the run time\n",
    "\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([4,5]), name = \"Weights_1\") #Initaliazing weight_1\n",
    "b1 = tf.Variable(tf.random_normal([1,5]), name = \"Bias_1\")\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([5,3]),  name = \"Weights_2\") #Initaliazing weight_2\n",
    "b2 = tf.Variable(tf.random_normal([1,3]), name = \"Bias_2\")\n",
    "#print \"weight_2 before Iteration: \",w2\n",
    "ind = sess.run(tf.argmax([0.021,0.0211,0.955]))\n",
    "print ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************weights before training*********************************\n",
      "                                                                                \n",
      "weight_1: \n",
      "[[-0.36223677  1.0483427   1.51492834  1.50437832  1.02970684]\n",
      " [-1.29111505  1.18258226 -0.07117686 -0.62687248 -0.50846922]\n",
      " [ 0.83629131 -1.49257708 -1.87965834 -0.20897792  2.74964333]\n",
      " [ 0.65472949 -0.24392195  0.20410123 -0.06860816 -0.22591133]]\n",
      "weight_2: \n",
      "[[ 1.30150247  0.18346155  1.51761091]\n",
      " [ 1.12819791  1.30550289  0.07093971]\n",
      " [-1.29603589  0.33217216  0.46735194]\n",
      " [-1.35928988 -0.41526243  0.28635716]\n",
      " [-0.91610318  0.27905968 -1.05662942]]\n",
      "-------------------------Training Result------------------------------------------\n",
      "                                                                                 \n",
      "losses after per 1000 iteration:  0.261651\n",
      "losses after per 1000 iteration:  0.0542542\n",
      "losses after per 1000 iteration:  0.0252577\n",
      "losses after per 1000 iteration:  0.0186576\n",
      "losses after per 1000 iteration:  0.0159436\n",
      "                                                                                         \n",
      "-------------------------------------Accuracy--------------------------------------------\n",
      "                                                                                         \n",
      "Accuracy on the model:  0.98\n",
      "***************************** weight after training *************************************\n",
      "weight_1 after trainig: \n",
      "[[-1.88777614  0.68739301  1.49397612  1.4329747   1.02457964]\n",
      " [-2.047472    1.290488   -0.04831168 -0.68840575 -0.51207012]\n",
      " [ 2.89769864 -2.63291407 -1.95214927 -0.19841573  2.74851632]\n",
      " [ 3.15624714 -0.90321141  0.14762859 -0.05796739 -0.22615005]]\n",
      "weight_2 after training: \n",
      "[[-0.19333185 -2.16113997  5.3570447 ]\n",
      " [ 5.42537117 -1.62297833 -1.29774594]\n",
      " [-0.85056281  0.86645007 -0.51240158]\n",
      " [-1.02379239  0.05773526 -0.52214611]\n",
      " [-0.54863417  0.74286979 -1.88790059]]\n",
      "-------------------------------------Results--------------------------------------------\n",
      "                                                                                         \n",
      "[0.0066831103, 0.030701991, 0.96261483]\n",
      "Flower_Iris_viginica\n"
     ]
    }
   ],
   "source": [
    "hidden_layer = tf.nn.sigmoid(tf.matmul(X_input,w1)+b1) \n",
    "output_layer = tf.nn.softmax(tf.matmul(hidden_layer,w2) + b2)\n",
    "\n",
    "losses = tf.losses.mean_squared_error(y_lable,output_layer)\n",
    "\n",
    "#optimizer = tf.train.AdamOptimizer(0.001).minimize(losses)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.09).minimize(losses)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print \"************************weights before training*********************************\"\n",
    "print \"                                                                                \"\n",
    "\n",
    "\n",
    "we1,we2 = sess.run([w1,w2])\n",
    "print \"weight_1: \"\n",
    "print we1\n",
    "print \"weight_2: \"\n",
    "print we2\n",
    "\n",
    "print \"-------------------------Training Result------------------------------------------\"\n",
    "print \"                                                                                 \"\n",
    "\n",
    "step_size = 10000\n",
    "for step in range(step_size):\n",
    "    \n",
    "    a,b,c,d,e,f = sess.run([hidden_layer,output_layer,losses,optimizer,w1,w2], feed_dict={X_input:x_lables,y_output:y_lable})\n",
    "\n",
    "    if step%2000==0:\n",
    "        print \"losses after per 1000 iteration: \",c\n",
    "\n",
    "print \"                                                                                         \"       \n",
    "correct_prediction = tf.equal(tf.argmax(output_layer,1), tf.argmax(y_output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print \"-------------------------------------Accuracy--------------------------------------------\"\n",
    "print \"                                                                                         \"\n",
    "\n",
    "print \"Accuracy on the model: \",accuracy.eval(feed_dict={X_input:x_lables, y_output:y_lable})\n",
    "\n",
    "check = tf.nn.sigmoid(tf.matmul([[6.8,3.2,5.9,2.3]],w1)+b1)\n",
    "output = tf.nn.softmax(tf.matmul(check,w2) + b2)\n",
    "\n",
    "print \"***************************** weight after training *************************************\"\n",
    "print \"weight_1 after trainig: \"\n",
    "print e\n",
    "print \"weight_2 after training: \"\n",
    "print f\n",
    "\n",
    "\n",
    "a,b = sess.run([check,output])\n",
    "#b = sess.run(output)\n",
    "print \"-------------------------------------Results--------------------------------------------\"\n",
    "print \"                                                                                         \"\n",
    "#print \"Result:  \",b\n",
    "convert_list = list(itertools.chain.from_iterable(b))\n",
    "print convert_list\n",
    "indx = sess.run(tf.argmax(convert_list))\n",
    "\n",
    "if(indx==0):\n",
    "    print \"Flower_Iris_Setosa\"\n",
    "elif(indx==1):\n",
    "    print \"Flower_Iris_Versicolor\"\n",
    "else:\n",
    "    print \"Flower_Iris_viginica\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
